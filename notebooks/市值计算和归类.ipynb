{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7acfb832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在连接到数据库 'mydb'...\n",
      "连接成功！准备执行SQL脚本...\n",
      "--------------------------------------------------\n",
      "✅ SQL脚本执行成功！\n",
      "✅ 数据表 'stock_cap_classification' 已成功创建并配置。\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# --- 1. 数据库连接配置 (使用你之前提供的参数) ---\n",
    "DB_HOST = 'localhost'\n",
    "DB_NAME = 'mydb'\n",
    "DB_USER = 'alan-hopiy'\n",
    "DB_PASS = ''\n",
    "DB_PORT = '5432'\n",
    "\n",
    "# 创建数据库连接URI\n",
    "db_uri = f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "# --- 2. 您提供的完整SQL建表语句 ---\n",
    "# 使用三引号 \"\"\" 来包裹多行SQL语句\n",
    "SQL_SCRIPT = \"\"\"\n",
    "-- 如果表已存在，则先删除，方便重新运行脚本\n",
    "DROP TABLE IF EXISTS stock_cap_classification;\n",
    "\n",
    "-- 创建市值分类结果表\n",
    "CREATE TABLE stock_cap_classification (\n",
    "    ts_code VARCHAR(10) NOT NULL,\n",
    "    name VARCHAR(50),\n",
    "    industry VARCHAR(50),\n",
    "    period_start_date DATE NOT NULL,\n",
    "    period_end_date DATE NOT NULL,\n",
    "    avg_total_mv NUMERIC(20, 4), -- 使用NUMERIC类型以保证精度，单位：万元\n",
    "    classification VARCHAR(20),\n",
    "    calculation_date DATE DEFAULT CURRENT_DATE, -- 记录计算当天的日期\n",
    "    PRIMARY KEY (ts_code, period_start_date, period_end_date) -- 复合主键\n",
    ");\n",
    "\n",
    "-- 为表和列添加注释，增加可读性\n",
    "COMMENT ON TABLE stock_cap_classification IS '存储A股按周期计算的市值分类结果';\n",
    "COMMENT ON COLUMN stock_cap_classification.ts_code IS '股票代码';\n",
    "COMMENT ON COLUMN stock_cap_classification.name IS '股票名称';\n",
    "COMMENT ON COLUMN stock_cap_classification.industry IS '所属行业';\n",
    "COMMENT ON COLUMN stock_cap_classification.period_start_date IS '市值计算周期的开始日期';\n",
    "COMMENT ON COLUMN stock_cap_classification.period_end_date IS '市值计算周期的结束日期';\n",
    "COMMENT ON COLUMN stock_cap_classification.avg_total_mv IS '周期内的日均总市值（万元）';\n",
    "COMMENT ON COLUMN stock_cap_classification.classification IS '市值分类（大/中/小市值公司）';\n",
    "COMMENT ON COLUMN stock_cap_classification.calculation_date IS '本条记录的计算日期';\n",
    "\"\"\"\n",
    "\n",
    "# --- 3. 执行SQL脚本的函数 ---\n",
    "def create_table_in_db():\n",
    "    \"\"\"\n",
    "    连接到数据库并执行SQL脚本来创建表和添加注释。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"正在连接到数据库 '{DB_NAME}'...\")\n",
    "        engine = create_engine(db_uri)\n",
    "\n",
    "        # 使用 with engine.connect() 来自动管理连接的开启和关闭\n",
    "        with engine.connect() as connection:\n",
    "            print(\"连接成功！准备执行SQL脚本...\")\n",
    "            \n",
    "            # 使用事务（transaction）来确保所有SQL语句要么全部成功，要么全部失败\n",
    "            # 这对于多步DDL（数据定义语言）操作是一个好习惯\n",
    "            with connection.begin() as transaction:\n",
    "                # SQLAlchemy 的 text() 函数用于安全地执行原始SQL\n",
    "                # 它可以直接处理包含多个语句的字符串\n",
    "                connection.execute(text(SQL_SCRIPT))\n",
    "            \n",
    "            print(\"--------------------------------------------------\")\n",
    "            print(\"✅ SQL脚本执行成功！\")\n",
    "            print(\"✅ 数据表 'stock_cap_classification' 已成功创建并配置。\")\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n❌ 操作失败！发生错误：\")\n",
    "        print(e)\n",
    "\n",
    "# --- 4. 运行主程序 ---\n",
    "if __name__ == \"__main__\":\n",
    "    create_table_in_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3d36d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现存档文件 'intermediate_results.parquet'，直接加载数据...\n",
      "数据加载成功，将跳过API获取和计算步骤。\n",
      "\n",
      "准备将结果写入数据库表 'stock_cap_classification'...\n",
      "数据成功写入数据库！\n",
      "数据库表 'stock_cap_classification' 中现在共有 5031 条记录。\n",
      "\n",
      "--- 任务执行完毕 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tushare as ts\n",
    "import time\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.types import VARCHAR, NUMERIC, DATE\n",
    "from typing import Union  # <--- 在这里添加这一行\n",
    "import os\n",
    "\n",
    "# --- 1. 配置参数 (无变动) ---\n",
    "TUSHARE_TOKEN = 'a872d82f46046d335ccf68ef591747ff66b9a9d598b40791b80f017a'\n",
    "pro = ts.pro_api(TUSHARE_TOKEN)\n",
    "DB_HOST = 'localhost'\n",
    "DB_NAME = 'mydb'\n",
    "DB_USER = 'alan-hopiy'\n",
    "DB_PASS = ''\n",
    "DB_PORT = '5432'\n",
    "db_uri = f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "engine = create_engine(db_uri)\n",
    "START_DATE = '20240101'\n",
    "END_DATE = '20241231'\n",
    "\n",
    "# --- 中间结果的存档文件名 (无变动) ---\n",
    "CACHE_FILE = 'intermediate_results.parquet'\n",
    "\n",
    "final_results = None\n",
    "\n",
    "# --- 断点续传逻辑 (无变动) ---\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    print(f\"发现存档文件 '{CACHE_FILE}'，直接加载数据...\")\n",
    "    final_results = pd.read_parquet(CACHE_FILE)\n",
    "    print(\"数据加载成功，将跳过API获取和计算步骤。\")\n",
    "else:\n",
    "    print(f\"未发现存档文件，将执行完整的数据获取流程。\")\n",
    "\n",
    "# 只有在未加载到缓存数据时，才执行下面的数据获取和处理流程\n",
    "if final_results is None:\n",
    "    # --- 2. 从数据库读取股票列表 (无变动) ---\n",
    "    try:\n",
    "        print(\"正在从数据库 stock_basic_info 表中读取A股上市公司列表...\")\n",
    "        # 核心逻辑调整：在这里加入筛选条件\n",
    "        query = \"\"\"\n",
    "        SELECT ts_code, name, industry \n",
    "        FROM stock_basic_info \n",
    "        WHERE \n",
    "            list_date <= '20240101' AND -- 筛选掉在统计周期内上市的新股\n",
    "            market IN ('主板', '创业板', '科创板') -- 暂时只包含这三个板块\n",
    "        \"\"\"\n",
    "        stock_list = pd.read_sql(query, engine)\n",
    "        print(f\"经过筛选，从数据库获取 {len(stock_list)} 家符合条件的上市公司信息。\")\n",
    "    except Exception as e:\n",
    "        print(f\"从数据库获取股票列表失败，错误：{e}\")\n",
    "        exit()\n",
    "\n",
    "    # --- 3. 获取数据函数 (内部逻辑不变) ---\n",
    "    def fetch_daily_data_for_stock(ts_code: str) -> Union[pd.DataFrame, None]:\n",
    "        try:\n",
    "            # 每次调用都是一次API请求\n",
    "            daily_df = pro.daily_basic(ts_code=ts_code, start_date=START_DATE, end_date=END_DATE, fields='ts_code,trade_date,total_mv')\n",
    "            if not daily_df.empty:\n",
    "                return daily_df\n",
    "        except Exception as e:\n",
    "            print(f\"获取 {ts_code} Tushare数据时出错: {e}\")\n",
    "        return None\n",
    "\n",
    "    # --- 修改：从多线程并行改为单线程串行获取数据 ---\n",
    "    all_daily_data = []\n",
    "    total_stocks = len(stock_list)\n",
    "    processed_count = 0\n",
    "    # 200次/分钟 -> 60秒/200次 = 0.3秒/次。设置0.33秒确保安全。\n",
    "    SLEEP_INTERVAL = 0.33 \n",
    "\n",
    "    print(f\"\\n开始通过【单线程串行】模式获取 {total_stocks} 只股票的日度总市值...\")\n",
    "    print(f\"为遵守API频率限制 (200次/分钟)，每次请求后将暂停 {SLEEP_INTERVAL:.2f} 秒。\")\n",
    "\n",
    "    # 使用 for 循环代替 ThreadPoolExecutor\n",
    "    for index, stock_row in stock_list.iterrows():\n",
    "        ts_code = stock_row['ts_code']\n",
    "        \n",
    "        # 调用函数获取数据\n",
    "        result_df = fetch_daily_data_for_stock(ts_code)\n",
    "        \n",
    "        processed_count += 1\n",
    "        if result_df is not None:\n",
    "            all_daily_data.append(result_df)\n",
    "        \n",
    "        # 打印进度 (逻辑不变)\n",
    "        if processed_count % 100 == 0 or processed_count == total_stocks:\n",
    "            print(f\"已完成 {processed_count}/{total_stocks} ({(processed_count / total_stocks) * 100:.2f}%)\")\n",
    "\n",
    "        # 核心新增：每次循环后暂停，以控制API请求频率\n",
    "        time.sleep(SLEEP_INTERVAL)\n",
    "\n",
    "    print(\"\\n所有股票的日度数据获取完成。\")\n",
    "    \n",
    "    # --- 4, 5, 6. 数据处理与整合 (无变动) ---\n",
    "    if not all_daily_data:\n",
    "        print(\"未能获取到任何股票的市值数据，程序终止。\")\n",
    "        exit()\n",
    "\n",
    "    market_values_df = pd.concat(all_daily_data, ignore_index=True)\n",
    "    \n",
    "    # 新增筛选：只保留在周期内有超过120天交易记录的股票\n",
    "    trade_day_counts = market_values_df.groupby('ts_code').size()\n",
    "    valid_ts_codes = trade_day_counts[trade_day_counts > 120].index\n",
    "    market_values_df = market_values_df[market_values_df['ts_code'].isin(valid_ts_codes)]\n",
    "    print(f\"筛选后，剩余 {len(valid_ts_codes)} 只股票（年内交易日 > 120天）进入市值计算。\")\n",
    "\n",
    "    print(\"正在计算每家公司的年内平均市值...\")\n",
    "    avg_market_value = market_values_df.groupby('ts_code')['total_mv'].mean().dropna().reset_index()\n",
    "    avg_market_value.rename(columns={'total_mv': 'avg_total_mv'}, inplace=True)\n",
    "    print(\"平均市值计算完成。\")\n",
    "    \n",
    "    print(\"正在根据平均市值进行大、中、小盘划分...\")\n",
    "    # 使用 30% 和 70% 分位数进行划分\n",
    "    p30 = avg_market_value['avg_total_mv'].quantile(0.3)\n",
    "    p70 = avg_market_value['avg_total_mv'].quantile(0.7)\n",
    "    print(f\"市值划分阈值：小市值上限 {p30:,.2f} 万元, 大市值下限 {p70:,.2f} 万元\")\n",
    "    def classify_market_cap(mv):\n",
    "        if mv >= p70: return '大盘股'\n",
    "        elif mv < p30: return '小盘股'\n",
    "        else: return '中盘股'\n",
    "    avg_market_value['classification'] = avg_market_value['avg_total_mv'].apply(classify_market_cap)\n",
    "    print(\"市值划分完成。\")\n",
    "\n",
    "    print(\"\\n正在整合最终结果...\")\n",
    "    final_results = pd.merge(stock_list, avg_market_value, on='ts_code', how='inner')\n",
    "    final_results['period_start_date'] = pd.to_datetime(START_DATE, format='%Y%m%d').date()\n",
    "    final_results['period_end_date'] = pd.to_datetime(END_DATE, format='%Y%m%d').date()\n",
    "    final_results = final_results[['ts_code', 'name', 'industry', 'period_start_date', 'period_end_date', 'avg_total_mv', 'classification']]\n",
    "\n",
    "    # --- 存档逻辑 (无变动) ---\n",
    "    try:\n",
    "        print(f\"正在将中间结果保存到存档文件 '{CACHE_FILE}'...\")\n",
    "        final_results.to_parquet(CACHE_FILE, index=False)\n",
    "        print(\"存档成功！\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存存档文件失败，错误：{e}\")\n",
    "\n",
    "# --- 7. 将结果写入数据库 (无变动) ---\n",
    "if final_results is not None and not final_results.empty:\n",
    "    try:\n",
    "        print(f\"\\n准备将结果写入数据库表 'stock_cap_classification'...\")\n",
    "        # 注意：此处 if_exists='replace' 会清空并重建表\n",
    "        dtype_mapping = {'ts_code': VARCHAR(10), 'name': VARCHAR(50), 'industry': VARCHAR(50), 'period_start_date': DATE, 'period_end_date': DATE, 'avg_total_mv': NUMERIC(20, 4), 'classification': VARCHAR(20)}\n",
    "        final_results.to_sql('stock_cap_classification', engine, if_exists='replace', index=False, dtype=dtype_mapping, method='multi')\n",
    "        print(\"数据成功写入数据库！\")\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            count = connection.execute(text(\"SELECT COUNT(1) FROM stock_cap_classification\")).scalar()\n",
    "            print(f\"数据库表 'stock_cap_classification' 中现在共有 {count} 条记录。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"数据写入数据库失败，错误：{e}\")\n",
    "else:\n",
    "    print(\"没有最终数据可写入数据库。\")\n",
    "\n",
    "print(\"\\n--- 任务执行完毕 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3038ecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始从数据库导出数据到Excel ---\n",
      "本次导出的文件将保存为: stock_cap_classification_20250611.xlsx\n",
      "正在连接到数据库 'mydb'...\n",
      "正在读取全部数据...\n",
      "成功读取 5031 行数据。\n",
      "正在将数据写入到: /Users/alan-hopiy/Documents/个人研究/基本面量化/stock_cap_classification_20250611.xlsx\n",
      "\n",
      "--- ✅ 导出成功！ ---\n",
      "文件已保存在: /Users/alan-hopiy/Documents/个人研究/基本面量化/stock_cap_classification_20250611.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from datetime import datetime  # <--- 新增：导入datetime模块用于获取当前日期\n",
    "\n",
    "# --- 1. 从config文件加载核心配置 ---\n",
    "import config\n",
    "\n",
    "DB_HOST = config.DB_HOST\n",
    "DB_NAME = config.DB_NAME\n",
    "DB_USER = config.DB_USER\n",
    "DB_PASS = config.DB_PASS\n",
    "DB_PORT = config.DB_PORT\n",
    "output_directory = config.BASE_OUTPUT_DIR\n",
    "\n",
    "# --- 2. 动态生成文件名 ---\n",
    "# 获取当前日期的字符串，格式为 YYYYMMDD (例如 '20250611')\n",
    "current_date_str = datetime.now().strftime('%Y%m%d')\n",
    "# 将日期加入文件名中\n",
    "output_filename = f\"stock_cap_classification_{current_date_str}.xlsx\"\n",
    "# 组合成完整的文件路径\n",
    "output_filepath = os.path.join(output_directory, output_filename)\n",
    "\n",
    "\n",
    "# --- 3. 主脚本逻辑 ---\n",
    "print(\"--- 开始从数据库导出数据到Excel ---\")\n",
    "print(f\"本次导出的文件将保存为: {output_filename}\")\n",
    "\n",
    "# 使用加载的配置构建URI\n",
    "db_uri = f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "try:\n",
    "    print(f\"正在连接到数据库 '{DB_NAME}'...\")\n",
    "    engine = create_engine(db_uri)\n",
    "    \n",
    "    table_name = 'stock_cap_classification'\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    \n",
    "    print(\"正在读取全部数据...\")\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f\"成功读取 {len(df)} 行数据。\")\n",
    "\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    print(f\"正在将数据写入到: {output_filepath}\")\n",
    "    df.to_excel(output_filepath, index=False)\n",
    "    \n",
    "    print(\"\\n--- ✅ 导出成功！ ---\")\n",
    "    print(f\"文件已保存在: {output_filepath}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ❌ 发生错误 ---\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c65f1f-e406-4c3f-a79b-5fcfa7cb5c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始更新数据库中的分类名称 ---\n",
      "正在执行更新操作...\n",
      "操作成功！共影响了 5031 行数据。\n",
      "\n",
      "--- 更新完成，正在验证结果 ---\n",
      "数据库中 'classification' 列当前所有的值为:\n",
      "- Small\n",
      "- Large\n",
      "- Mid\n",
      "\n",
      "✅ 任务成功完成！\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# --- 1. 配置参数 (请确保与您的配置一致) ---\n",
    "DB_HOST = 'localhost'\n",
    "DB_NAME = 'mydb'\n",
    "DB_USER = 'alan-hopiy'\n",
    "DB_PASS = ''  # 无密码\n",
    "DB_PORT = '5432'\n",
    "TABLE_NAME = 'stock_cap_classification'\n",
    "\n",
    "# 构建数据库连接URI\n",
    "db_uri = f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "# --- 2. 定义SQL更新语句 ---\n",
    "# 使用 CASE 语句可以一次性完成所有替换，效率最高\n",
    "update_sql = f\"\"\"\n",
    "UPDATE {TABLE_NAME}\n",
    "SET classification = CASE\n",
    "    WHEN classification = '大盘股' THEN 'Large'\n",
    "    WHEN classification = '中盘股' THEN 'Mid'\n",
    "    WHEN classification = '小盘股' THEN 'Small'\n",
    "    ELSE classification -- 保留其他可能的值不变\n",
    "END\n",
    "WHERE classification IN ('大盘股', '中盘股', '小盘股'); -- 只对需要修改的行进行操作，提高效率\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- 开始更新数据库中的分类名称 ---\")\n",
    "\n",
    "try:\n",
    "    engine = create_engine(db_uri)\n",
    "    with engine.connect() as connection:\n",
    "        # 开始一个事务\n",
    "        with connection.begin() as transaction:\n",
    "            print(\"正在执行更新操作...\")\n",
    "            # 执行更新语句\n",
    "            result = connection.execute(text(update_sql))\n",
    "            print(f\"操作成功！共影响了 {result.rowcount} 行数据。\")\n",
    "            # 事务在此处自动提交\n",
    "\n",
    "    print(\"\\n--- 更新完成，正在验证结果 ---\")\n",
    "\n",
    "    # --- 3. 验证更新后的结果 ---\n",
    "    with engine.connect() as connection:\n",
    "        verify_sql = f\"SELECT DISTINCT classification FROM {TABLE_NAME};\"\n",
    "        verification_result = connection.execute(text(verify_sql)).fetchall()\n",
    "        \n",
    "        print(\"数据库中 'classification' 列当前所有的值为:\")\n",
    "        for row in verification_result:\n",
    "            print(f\"- {row[0]}\")\n",
    "\n",
    "    print(\"\\n✅ 任务成功完成！\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 操作失败，发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5deb5d9-f0bf-4a3b-810d-61092af3badc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 准备从数据库表 'stock_cap_classification' 中读取前10行数据 ---\n",
      "正在连接数据库并执行查询...\n",
      "\n",
      "✅ 查询成功！以下是表的前10行内容：\n",
      "\n",
      "     ts_code  name industry period_start_date period_end_date  avg_total_mv  \\\n",
      "0  000020.SZ  深华发A      元器件        2024-01-01      2024-12-31       36.0873   \n",
      "1  000021.SZ   深科技      元器件        2024-01-01      2024-12-31      238.6745   \n",
      "2  000025.SZ   特力A      综合类        2024-01-01      2024-12-31       66.7836   \n",
      "3  000026.SZ   飞亚达       服饰        2024-01-01      2024-12-31       40.3415   \n",
      "4  000027.SZ  深圳能源     火力发电        2024-01-01      2024-12-31      319.4096   \n",
      "5  000028.SZ  国药一致     医药商业        2024-01-01      2024-12-31      171.7735   \n",
      "6  000029.SZ  深深房A     区域地产        2024-01-01      2024-12-31      124.7122   \n",
      "7  000030.SZ  富奥股份     汽车配件        2024-01-01      2024-12-31       89.3700   \n",
      "8  000031.SZ   大悦城     全国地产        2024-01-01      2024-12-31      118.3465   \n",
      "9  000032.SZ  深桑达A     建筑工程        2024-01-01      2024-12-31      190.0538   \n",
      "\n",
      "  classification  \n",
      "0            Mid  \n",
      "1          Large  \n",
      "2            Mid  \n",
      "3            Mid  \n",
      "4          Large  \n",
      "5          Large  \n",
      "6          Large  \n",
      "7          Large  \n",
      "8          Large  \n",
      "9          Large  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# --- 1. 配置参数 (请确保与您的配置一致) ---\n",
    "DB_HOST = 'localhost'\n",
    "DB_NAME = 'mydb'\n",
    "DB_USER = 'alan-hopiy'\n",
    "DB_PASS = ''  # 无密码\n",
    "DB_PORT = '5432'\n",
    "TABLE_NAME = 'stock_cap_classification'\n",
    "\n",
    "# 构建数据库连接URI\n",
    "db_uri = f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "print(f\"--- 准备从数据库表 '{TABLE_NAME}' 中读取前10行数据 ---\")\n",
    "\n",
    "try:\n",
    "    # 创建数据库引擎\n",
    "    engine = create_engine(db_uri)\n",
    "\n",
    "    # 定义SQL查询语句，使用 LIMIT 10 获取前10条记录\n",
    "    query = f\"SELECT * FROM {TABLE_NAME} LIMIT 10;\"\n",
    "\n",
    "    print(\"正在连接数据库并执行查询...\")\n",
    "    \n",
    "    # 使用pandas读取SQL查询结果\n",
    "    df_head = pd.read_sql(query, engine)\n",
    "\n",
    "    print(\"\\n✅ 查询成功！以下是表的前10行内容：\\n\")\n",
    "    \n",
    "    # 直接打印DataFrame，pandas会自动进行格式化，非常清晰\n",
    "    print(df_head)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 操作失败，发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dec0cd47-d82f-4843-a004-ba9280b00bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始将 'stock_cap_classification' 表中 'avg_total_mv' 列的单位从 '万' 修改为 '亿' ---\n",
      "正在执行单位更新操作...\n",
      "操作成功！共更新了 5031 行数据。\n",
      "\n",
      "--- 更新完成，正在查询前10行数据以验证结果 ---\n",
      "✅ 单位修改成功！以下是更新后的数据示例（市值单位已是'亿'）:\n",
      "\n",
      "     ts_code  name  avg_total_mv classification\n",
      "0  000020.SZ  深华发A       36.0873            中盘股\n",
      "1  000021.SZ   深科技      238.6745            大盘股\n",
      "2  000025.SZ   特力A       66.7836            中盘股\n",
      "3  000026.SZ   飞亚达       40.3415            中盘股\n",
      "4  000027.SZ  深圳能源      319.4096            大盘股\n",
      "5  000028.SZ  国药一致      171.7735            大盘股\n",
      "6  000029.SZ  深深房A      124.7122            大盘股\n",
      "7  000030.SZ  富奥股份       89.3700            大盘股\n",
      "8  000031.SZ   大悦城      118.3465            大盘股\n",
      "9  000032.SZ  深桑达A      190.0538            大盘股\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# --- 1. 配置参数 (请确保与您的配置一致) ---\n",
    "DB_HOST = 'localhost'\n",
    "DB_NAME = 'mydb'\n",
    "DB_USER = 'alan-hopiy'\n",
    "DB_PASS = ''  # 无密码\n",
    "DB_PORT = '5432'\n",
    "TABLE_NAME = 'stock_cap_classification'\n",
    "COLUMN_TO_UPDATE = 'avg_total_mv'\n",
    "\n",
    "# 构建数据库连接URI\n",
    "db_uri = f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "# --- 2. 定义SQL更新语句 ---\n",
    "# 将目标列的每一个值都除以10000\n",
    "update_sql = f\"\"\"\n",
    "UPDATE {TABLE_NAME}\n",
    "SET {COLUMN_TO_UPDATE} = {COLUMN_TO_UPDATE} / 10000;\n",
    "\"\"\"\n",
    "\n",
    "print(f\"--- 开始将 '{TABLE_NAME}' 表中 '{COLUMN_TO_UPDATE}' 列的单位从 '万' 修改为 '亿' ---\")\n",
    "\n",
    "try:\n",
    "    engine = create_engine(db_uri)\n",
    "    with engine.connect() as connection:\n",
    "        # 使用事务确保操作的原子性\n",
    "        with connection.begin() as transaction:\n",
    "            print(\"正在执行单位更新操作...\")\n",
    "            # 执行更新\n",
    "            result = connection.execute(text(update_sql))\n",
    "            print(f\"操作成功！共更新了 {result.rowcount} 行数据。\")\n",
    "            # 事务在此处自动提交\n",
    "\n",
    "    print(\"\\n--- 更新完成，正在查询前10行数据以验证结果 ---\")\n",
    "\n",
    "    # --- 3. 验证更新后的结果 ---\n",
    "    with engine.connect() as connection:\n",
    "        # 查询前10行，重点关注修改后的 avg_total_mv 列\n",
    "        verify_sql = f\"SELECT ts_code, name, avg_total_mv, classification FROM {TABLE_NAME} LIMIT 10;\"\n",
    "        df_new = pd.read_sql(verify_sql, engine)\n",
    "        \n",
    "        print(\"✅ 单位修改成功！以下是更新后的数据示例（市值单位已是'亿'）:\\n\")\n",
    "        # 设置pandas显示格式，让小数更清晰\n",
    "        pd.options.display.float_format = '{:,.4f}'.format\n",
    "        print(df_new)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 操作失败，发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea812045-5d2d-4d6f-804f-9552c20490a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
